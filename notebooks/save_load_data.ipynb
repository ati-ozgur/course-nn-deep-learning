{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial version from https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/save_load_params.html\n",
    "from __future__ import print_function\n",
    "\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version should be greater than '1.2.1'\n",
    "mx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if one exists, else use CPU\n",
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n",
    "\n",
    "# MNIST images are 28x28. Total pixels in input layer is 28x28 = 784\n",
    "num_inputs = 784\n",
    "# Clasify the images into one of the 10 digits\n",
    "num_outputs = 10\n",
    "# 64 images in a batch\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=True).transform_first(transforms.ToTensor()),\n",
    "                                   batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple convolutional network\n",
    "def get_lenet():\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        # First convolution\n",
    "        net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        # Second convolution\n",
    "        net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        # Flatten the output before the fully connected layers\n",
    "        net.add(gluon.nn.Flatten())\n",
    "        # First fully connected layers with 512 neurons\n",
    "        net.add(gluon.nn.Dense(512, activation=\"relu\"))\n",
    "        # Second fully connected layer with as many neurons as the number of classes\n",
    "        net.add(gluon.nn.Dense(num_outputs))\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple mlp network\n",
    "def get_mlp():   \n",
    "    net = gluon.nn.Sequential()\n",
    "\n",
    "    with net.name_scope():\n",
    "        # First convolution\n",
    "        net.add(gluon.nn.Dense(256))\n",
    "        net.add(gluon.nn.Dense(num_outputs))\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a given model using MNIST data\n",
    "def train_model(model):\n",
    "    # Initialize the parameters with Xavier initializer\n",
    "    model.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "    # Use cross entropy loss\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    # Use Adam optimizer\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'sgd', {'learning_rate': .001})\n",
    "\n",
    "    # Train for one epoch\n",
    "    for epoch in range(1):\n",
    "        # Iterate through the images and labels in the training data\n",
    "        for batch_num, (data, label) in enumerate(train_data):\n",
    "            # get the images and labels\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            # Ask autograd to record the forward pass\n",
    "            with autograd.record():\n",
    "                # Run the forward pass\n",
    "                output = model(data)\n",
    "                # Compute the loss\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            # Update parameters\n",
    "            trainer.step(data.shape[0])\n",
    "\n",
    "            # Print loss once in a while\n",
    "            if batch_num % 50 == 0:\n",
    "                curr_loss = nd.mean(loss).asscalar()\n",
    "                print(\"Epoch: %d; Batch %d; Loss %f\" % (epoch, batch_num, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_lenet()\n",
    "train_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"net_lenet.params\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = get_lenet()\n",
    "new_net.load_parameters(file_name, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def verify_loaded_model(net):\n",
    "    \"\"\"Run inference using ten random images.\n",
    "    Print both input and output of the model\"\"\"\n",
    "\n",
    "    def transform(data, label):\n",
    "        return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "\n",
    "    # Load ten random images from the test dataset\n",
    "    sample_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                  10, shuffle=True)\n",
    "\n",
    "    for data, label in sample_data:\n",
    "\n",
    "        # Display the images\n",
    "        img = nd.transpose(data, (1,0,2,3))\n",
    "        img = nd.reshape(img, (28,10*28,1))\n",
    "        imtiles = nd.tile(img, (1,1,3))\n",
    "        plt.imshow(imtiles.asnumpy())\n",
    "        plt.show()\n",
    "\n",
    "        # Display the predictions\n",
    "        data = nd.transpose(data, (0, 3, 1, 2))\n",
    "        out = net(data.as_in_context(ctx))\n",
    "        predictions = nd.argmax(out, axis=1)\n",
    "        print('Model predictions: ', predictions.asnumpy())\n",
    "\n",
    "        break\n",
    "\n",
    "verify_loaded_model(new_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
