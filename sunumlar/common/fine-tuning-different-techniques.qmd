# Fine tuning (alignment) different techniques

## fine tuning different models

![](../images/fine-tuning-different-models.png)

- SFT (Supervised Fine Tuning)
- RLHF (Reinforcement Learning Human Feedback)
- PPO (Proximal Policy Optimization)
- DPO (Direct Preference Optimization)

## GPT Assistant training pipeline

![](../images/GPT-Assistant-training-pipeline.png)

- [Andrej Karpathy: State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)

## Fine tuning thoughts

![](../images/fine-tuning-thoughts.png)

- [Andrej Karpathy: State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)
